{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdcdee14",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eda8092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\administrator\\anaconda3\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: outcome in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.0.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2dcddbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ce10d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'C:\\Users\\Administrator\\Downloads\\chromedriver_win32.zip\\chromedriver.exe')\n",
    "driver.maximize_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41cf876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b946a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.',\n",
       " '2.',\n",
       " '3.',\n",
       " '4.',\n",
       " '5.',\n",
       " '6.',\n",
       " '7.',\n",
       " '8.',\n",
       " '9.',\n",
       " '10.',\n",
       " '11.',\n",
       " '12.',\n",
       " '13.',\n",
       " '14.',\n",
       " '15.',\n",
       " '16.',\n",
       " '17.',\n",
       " '18.',\n",
       " '19.',\n",
       " '20.',\n",
       " '21.',\n",
       " '22.',\n",
       " '23.',\n",
       " '24.',\n",
       " '25.',\n",
       " '26.',\n",
       " '27.',\n",
       " '28.',\n",
       " '29.',\n",
       " '30.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = []\n",
    "ranks = driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\")\n",
    "for i in ranks: \n",
    "    rank.append(i.text)\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94c0b611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Baby Shark Dance\"[4]',\n",
       " '\"Despacito\"[7]',\n",
       " '\"Johny Johny Yes Papa\"[14]',\n",
       " '\"Shape of You\"[15]',\n",
       " '\"Bath Song\"[17]',\n",
       " '\"See You Again\"[18]',\n",
       " '\"Phonics Song with Two Words\"[23]',\n",
       " '\"Uptown Funk\"[24]',\n",
       " '\"Learning Colors – Colorful Eggs on a Farm\"[25]',\n",
       " '\"Wheels on the Bus\"[26]',\n",
       " '\"Gangnam Style\"[27]',\n",
       " '\"Masha and the Bear – Recipe for Disaster\"[32]',\n",
       " '\"Dame Tu Cosita\"[33]',\n",
       " '\"Sugar\"[34]',\n",
       " '\"Roar\"[35]',\n",
       " '\"Counting Stars\"[36]',\n",
       " '\"Axel F\"[37]',\n",
       " '\"Sorry\"[38]',\n",
       " '\"Thinking Out Loud\"[39]',\n",
       " '\"Baa Baa Black Sheep\"[40]',\n",
       " '\"Dark Horse\"[41]',\n",
       " '\"Faded\"[42]',\n",
       " '\"Girls Like You\"[43]',\n",
       " '\"Let Her Go\"[44]',\n",
       " '\"Waka Waka (This Time for Africa)\"[45]',\n",
       " '\"Perfect\"[46]',\n",
       " '\"Bailando\"[47]',\n",
       " '\"Lean On\"[48]',\n",
       " '\"Humpty the train on a fruits ride\"[49]',\n",
       " '\"Shake It Off\"[50]']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = []\n",
    "names = driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\")\n",
    "for i in names:\n",
    "    name.append(i.text)\n",
    "    \n",
    "name    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b2fa2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Pinkfong Baby Shark - Kids' Songs & Stories\",\n",
       " 'Luis Fonsi',\n",
       " 'LooLoo Kids',\n",
       " 'Ed Sheeran',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'Wiz Khalifa',\n",
       " 'ChuChu TV',\n",
       " 'Mark Ronson',\n",
       " 'Miroshka TV',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'Psy',\n",
       " 'Get Movies',\n",
       " 'El Chombo',\n",
       " 'Maroon 5',\n",
       " 'Katy Perry',\n",
       " 'OneRepublic',\n",
       " 'Crazy Frog',\n",
       " 'Justin Bieber',\n",
       " 'Ed Sheeran',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'Katy Perry',\n",
       " 'Alan Walker',\n",
       " 'Maroon 5',\n",
       " 'Passenger',\n",
       " 'Shakira',\n",
       " 'Ed Sheeran',\n",
       " 'Enrique Iglesias',\n",
       " 'Major Lazer',\n",
       " 'Kiddiestv Hindi – Nursery Rhymes & Kids Songs',\n",
       " 'Taylor Swift']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist = []\n",
    "artists = driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[3]\")\n",
    "for i in artists:\n",
    "    artist.append(i.text)\n",
    "    \n",
    "artist    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7af555d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['June 17, 2016',\n",
       " 'January 12, 2017',\n",
       " 'October 8, 2016',\n",
       " 'January 30, 2017',\n",
       " 'May 2, 2018',\n",
       " 'April 6, 2015',\n",
       " 'March 6, 2014',\n",
       " 'November 19, 2014',\n",
       " 'February 27, 2018',\n",
       " 'May 24, 2018',\n",
       " 'July 15, 2012',\n",
       " 'January 31, 2012',\n",
       " 'April 5, 2018',\n",
       " 'January 14, 2015',\n",
       " 'September 5, 2013',\n",
       " 'May 31, 2013',\n",
       " 'June 16, 2009',\n",
       " 'October 22, 2015',\n",
       " 'October 7, 2014',\n",
       " 'June 25, 2018',\n",
       " 'February 20, 2014',\n",
       " 'December 3, 2015',\n",
       " 'May 31, 2018',\n",
       " 'July 25, 2012',\n",
       " 'June 4, 2010',\n",
       " 'November 9, 2017',\n",
       " 'April 11, 2014',\n",
       " 'March 22, 2015',\n",
       " 'January 26, 2018',\n",
       " 'August 18, 2014']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = []\n",
    "dates = driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\")\n",
    "for i in dates:\n",
    "    date.append(i.text)\n",
    "    \n",
    "date    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9725abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11.83',\n",
       " '8.02',\n",
       " '6.54',\n",
       " '5.86',\n",
       " '5.81',\n",
       " '5.71',\n",
       " '5.04',\n",
       " '4.77',\n",
       " '4.74',\n",
       " '4.69',\n",
       " '4.62',\n",
       " '4.52',\n",
       " '4.15',\n",
       " '3.79',\n",
       " '3.69',\n",
       " '3.69',\n",
       " '3.63',\n",
       " '3.61',\n",
       " '3.52',\n",
       " '3.44',\n",
       " '3.40',\n",
       " '3.38',\n",
       " '3.35',\n",
       " '3.35',\n",
       " '3.34',\n",
       " '3.31',\n",
       " '3.30',\n",
       " '3.29',\n",
       " '3.24',\n",
       " '3.23']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = []\n",
    "views = driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\")\n",
    "for i in views:\n",
    "    view.append(i.text)\n",
    "    \n",
    "view    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c18ae348",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f7a627",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecc35aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88b0c7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'C:\\Users\\Administrator\\Downloads\\chromedriver_win32.zip\\chromedriver.exe')\n",
    "driver.maximize_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bad61749",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.bcci.tv/international/fixtures'\n",
    "driver.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f50330ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn = driver.find_element(By.XPATH,\"//li[@class='nav-item']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b81e51dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First-Class Match -',\n",
       " '2nd ODI -',\n",
       " '1st T20I -',\n",
       " '3rd ODI -',\n",
       " '2nd T20I -',\n",
       " '1st Test -',\n",
       " '3rd T20I -']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_title = []\n",
    "match_tag = driver.find_elements(By.XPATH,\"//span[@class='matchOrderText ng-binding ng-scope']\")\n",
    "for i in match_tag:\n",
    "    match_title.append(i.text)\n",
    "    \n",
    "match_title       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "719f75d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INDIA A IN BANGLADESH MULTI DAY SERIES',\n",
       " 'Stumps Day 1',\n",
       " 'INDIA TOUR OF BANGLADESH ODI SERIES 2022-23',\n",
       " 'AUSTRALIA WOMEN TOUR OF INDIA 2022',\n",
       " 'INDIA TOUR OF BANGLADESH ODI SERIES 2022-23',\n",
       " 'AUSTRALIA WOMEN TOUR OF INDIA 2022',\n",
       " 'INDIA TOUR OF BANGLADESH TEST SERIES 2022-23',\n",
       " 'AUSTRALIA WOMEN TOUR OF INDIA 2022']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = []\n",
    "series_num = driver.find_elements(By.XPATH,\"//span[@class='ng-binding']\")\n",
    "for i in series_num:\n",
    "    series.append(i.text)\n",
    "    \n",
    "    \n",
    "series    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "397c0690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11:30 AM IST',\n",
       " '7:00 PM IST',\n",
       " '11:30 AM IST',\n",
       " '7:00 PM IST',\n",
       " '9:30 AM IST',\n",
       " '7:00 PM IST',\n",
       " '7:00 PM IST']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = []\n",
    "time_ment = driver.find_elements(By.XPATH,\"//h5[@class='text-right ng-binding']\")\n",
    "for i in time_ment:\n",
    "    time.append(i.text)\n",
    "    \n",
    "time    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76b4ed1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6 DEC 2022',\n",
       " '7 DEC 2022',\n",
       " '9 DEC 2022',\n",
       " '10 DEC 2022',\n",
       " '11 DEC 2022',\n",
       " '14 DEC 2022',\n",
       " '14 DEC 2022',\n",
       " '17 DEC 2022']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = []\n",
    "date_tag = driver.find_elements(By.XPATH,\"//h5[@class='ng-binding']\")\n",
    "for i in date_tag:\n",
    "    date.append(i.text)\n",
    "    \n",
    "date    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75eb15de",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e9d66b",
   "metadata": {},
   "source": [
    "## Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "216f8cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "793adb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'C:\\Users\\Administrator\\Downloads\\chromedriver_win32.zip\\chromedriver.exe')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d267f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.naukri.com/hr-recruiters-consultants'\n",
    "driver.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ace8a009",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn = driver.find_element(By.XPATH,\"//input[@class='sugInp']\")\n",
    "search_btn.send_keys(\"Data Science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bea5f424",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn = driver.find_element(By.XPATH,\"//button[@class='fl qsbSrch blueBtn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d2cf5e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aakash Harit',\n",
       " 'shravan Kumar Gaddam',\n",
       " 'MARSIAN Technologies LLP',\n",
       " 'Anik Agrawal',\n",
       " 'subhas patel',\n",
       " 'Abhishek - Only Analytics Hiring - India and',\n",
       " 'Institute for Financial Management and Resear',\n",
       " 'Balu Ramesh',\n",
       " 'Asif Lucknowi',\n",
       " 'InstaFinancials',\n",
       " 'Kalpana Dumpala',\n",
       " 'Mubarak',\n",
       " 'Kushal Rastogi',\n",
       " 'Mahesh Babu Channa',\n",
       " 'Vaishnavi Kudalkar',\n",
       " 'Priyanka Akiri',\n",
       " 'Kapil Devang',\n",
       " 'Sakshi Chhikara',\n",
       " 'Ruchi Dhote',\n",
       " 'Manisha Yadav',\n",
       " 'Riya Rajesh',\n",
       " 'Rashmi Bhattacharjee',\n",
       " 'Faizan Kareem',\n",
       " 'Rithika dadwal',\n",
       " 'Sandhya Khandagale',\n",
       " 'Shaun Rao',\n",
       " 'Azahar Shaikh',\n",
       " 'Manas',\n",
       " 'kumar',\n",
       " 'Sunil Vedula',\n",
       " 'Rajat Kumar',\n",
       " 'Dhruv Dev Dubey',\n",
       " 'Jayanth N',\n",
       " 'Daniel Vaz',\n",
       " 'Avodha',\n",
       " 'Priya Khare',\n",
       " 'Amit Sharma',\n",
       " 'Kanan',\n",
       " 'Shashikant Chaudhary',\n",
       " 'Brad',\n",
       " 'Rutuja Pawar',\n",
       " 'Madhusudhan Sridhar',\n",
       " 'Ankit Sinha',\n",
       " 'Gaurav Chouhan',\n",
       " 'Rashi Kacker',\n",
       " 'Ashwini',\n",
       " 'Balaji Kolli',\n",
       " 'Rajani Nagaraj',\n",
       " 'ROHIT Kumar',\n",
       " 'Amir Chowdhury']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = []\n",
    "names = driver.find_elements(By.XPATH,\"//span[@class='fl ellipsis']\")\n",
    "for i in names:\n",
    "    name.append(i.text)\n",
    "    \n",
    "name    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4f77ef7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HR Manager',\n",
       " 'Company Recruiter',\n",
       " 'Company HR',\n",
       " 'Company Recruiter',\n",
       " 'Founder CEO',\n",
       " 'Recruitment Lead Consultant',\n",
       " 'Programme Manager',\n",
       " 'HR Administrator',\n",
       " 'Director',\n",
       " 'Human Resource',\n",
       " 'Executive Hiring',\n",
       " 'Company HR',\n",
       " 'Company HR',\n",
       " 'HR Team Lead',\n",
       " 'HR Executive',\n",
       " 'HR Manager',\n",
       " 'HR Manager',\n",
       " 'Assistant Manager HR',\n",
       " 'Senior Executive Talent Acquisition',\n",
       " 'HR Executive',\n",
       " 'Manager Talent Acquisition',\n",
       " 'HR Head',\n",
       " 'HR MANAGER',\n",
       " 'HR Recruiter',\n",
       " 'HR Recruiter',\n",
       " 'Manager Human Resources',\n",
       " 'Company Recruiter',\n",
       " 'Lead Talent acquisition',\n",
       " 'Proprietor',\n",
       " 'CEO',\n",
       " 'Founder CEO',\n",
       " 'Company Recruitment Head',\n",
       " 'Project Manager',\n",
       " 'Partner',\n",
       " 'Business Development Associate',\n",
       " 'Senior Manager',\n",
       " 'Consultant',\n",
       " 'senior technology instructor',\n",
       " 'HR Recruiter/HR Excutive',\n",
       " 'Manager, Technical Recruiting',\n",
       " 'Technical Recruiter',\n",
       " 'Erp Implementer',\n",
       " 'Head Analytics',\n",
       " 'Chief Technical Officer',\n",
       " 'Sr Product Manager',\n",
       " 'Director Global Delivery',\n",
       " 'Co Founder',\n",
       " 'HR Manager',\n",
       " 'Architect',\n",
       " 'Managing Partner']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desination = []\n",
    "desntns = driver.find_elements(By.XPATH,\"//span[@class='ellipsis clr']\")\n",
    "for i in desntns:\n",
    "    desination.append(i.text)\n",
    "    \n",
    "desination   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "46feee58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aakash Harit',\n",
       " 'Data Science Network',\n",
       " 'shravan Kumar Gaddam',\n",
       " 'Shore Infotech India Pvt. Ltd',\n",
       " 'MARSIAN Technologies LLP',\n",
       " 'MARSIAN Technologies LLP',\n",
       " 'Anik Agrawal',\n",
       " 'Enerlytics Software Solutions Pvt Ltd',\n",
       " 'subhas patel',\n",
       " 'LibraryXProject',\n",
       " 'Abhishek - Only Analytics Hiring - India and',\n",
       " 'Apidel Technologies Division of Transpower',\n",
       " 'Institute for Financial Management and Resear',\n",
       " 'IFMR',\n",
       " 'Balu Ramesh',\n",
       " 'Techvantage Systems Pvt Ltd',\n",
       " 'Asif Lucknowi',\n",
       " 'Weupskill- Live Wire India',\n",
       " 'InstaFinancials',\n",
       " 'CBL Data Science Private Limited',\n",
       " 'Kalpana Dumpala',\n",
       " 'Innominds Software',\n",
       " 'Mubarak',\n",
       " 'MoneyTap',\n",
       " 'Kushal Rastogi',\n",
       " 'QuantMagnum Technologies Pvt. Ltd.',\n",
       " 'Mahesh Babu Channa',\n",
       " 'SocialPrachar.com',\n",
       " 'Vaishnavi Kudalkar',\n",
       " 'Codeachive learning',\n",
       " 'Priyanka Akiri',\n",
       " 'Infinitive Software Solutions',\n",
       " 'Kapil Devang',\n",
       " 'BISP Solutions',\n",
       " 'Sakshi Chhikara',\n",
       " 'BIZ INFOTECNO PRIVATE LIMITED',\n",
       " 'Ruchi Dhote',\n",
       " 'Bristlecone India Ltd',\n",
       " 'Manisha Yadav',\n",
       " 'Easi Tax',\n",
       " 'Riya Rajesh',\n",
       " 'Novelworx Digital Solutions',\n",
       " 'Rashmi Bhattacharjee',\n",
       " 'AXESTRACK SOFTWARE SOLUTIONS PRIVATE...',\n",
       " 'Faizan Kareem',\n",
       " 'FirstTech Consaltants Pvt.Ltd',\n",
       " 'Rithika dadwal',\n",
       " 'Affine Analytics',\n",
       " 'Sandhya Khandagale',\n",
       " 'Compumatrice Multimedia Pvt Ltd',\n",
       " 'Shaun Rao',\n",
       " 'Exela Technologies',\n",
       " 'Azahar Shaikh',\n",
       " 'NEAL ANALYTICS SERVICES PVT LTD',\n",
       " 'Manas',\n",
       " 'Autumn Leaf Consulting Services Private...',\n",
       " 'kumar',\n",
       " 'trainin',\n",
       " 'Sunil Vedula',\n",
       " 'Nanoprecise Sci Corp',\n",
       " 'Rajat Kumar',\n",
       " 'R.S Consultancy &amp; Services',\n",
       " 'Dhruv Dev Dubey',\n",
       " 'Confidential',\n",
       " 'Jayanth N',\n",
       " 'Dollarbird Information Services Pvt, Ltd',\n",
       " 'Daniel Vaz',\n",
       " 'Aquis Search',\n",
       " 'Avodha',\n",
       " 'Nikitha Palaparthi',\n",
       " 'Priya Khare',\n",
       " 'Independent Consultant',\n",
       " 'Amit Sharma',\n",
       " 'ASCO consulting',\n",
       " 'Kanan',\n",
       " 'NY INST',\n",
       " 'Shashikant Chaudhary',\n",
       " '3D India Staffing Research &amp; Consulting...',\n",
       " 'Brad',\n",
       " 'O.C. Tanner',\n",
       " 'Rutuja Pawar',\n",
       " 'Demand Matrix',\n",
       " 'Madhusudhan Sridhar',\n",
       " 'MADHUSUDHAN SRIDHAR',\n",
       " 'Ankit Sinha',\n",
       " 'Suntech Global',\n",
       " 'Gaurav Chouhan',\n",
       " 'Strategic Consulting Lab',\n",
       " 'Rashi Kacker',\n",
       " 'Impel Labs Pvt. Ltd.',\n",
       " 'Ashwini',\n",
       " 'MRP Advisers',\n",
       " 'Balaji Kolli',\n",
       " 'Saras Solutions India Pvt Ltd',\n",
       " 'Rajani Nagaraj',\n",
       " 'WildJasmine',\n",
       " 'ROHIT Kumar',\n",
       " 'LNT Private Limited',\n",
       " 'Amir Chowdhury',\n",
       " 'Granular.ai']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company = []\n",
    "compny = driver.find_elements(By.XPATH,\"//a[@class='ellipsis']\")\n",
    "for i in compny:\n",
    "    company.append(i.text)\n",
    "    \n",
    "company    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "09ab2a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Delhi',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Pune',\n",
       " 'Ahmedabad',\n",
       " 'UK - (london)',\n",
       " 'Vadodara / Baroda',\n",
       " 'Chennai',\n",
       " 'Trivandrum',\n",
       " 'Indore',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Mumbai',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Mumbai',\n",
       " 'Hyderabad',\n",
       " 'Bhopal',\n",
       " 'Chandigarh',\n",
       " 'Pune',\n",
       " 'Navi Mumbai',\n",
       " 'Cochin',\n",
       " 'Delhi',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Pune',\n",
       " 'Pune',\n",
       " 'Pune',\n",
       " 'Pune',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Delhi',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Mysoru / Mysore',\n",
       " 'Mumbai',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'New Delhi',\n",
       " 'Chennai',\n",
       " 'Aligarh',\n",
       " 'Salt Lake City',\n",
       " 'Pune',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Mumbai',\n",
       " 'Indore',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'MYSORE',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Mumbai']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location = []\n",
    "loctn = driver.find_elements(By.XPATH,\"//small[@class='ellipsis']\")\n",
    "for i in loctn:\n",
    "    location.append(i.text)\n",
    "    \n",
    "location    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c5848b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Classic ASP Developer, Internet Marketing Professional, Data Science SME, Content Writers, SEO Professional, Revenue Professional',\n",
       " '.Net, Java, Data Science, Linux Administration, Sql Server Development, Winforms, Wcf Services, Wpf, Telecom Engineering, Technical Management, Software',\n",
       " 'Data Science, Artificial Intelligence, Machine Learning, Business Analytics, Deep Learning, statistics, Data Analytics, Data Analysis, support vector machine',\n",
       " 'Mean Stack, javascript, angularjs, mongodb, Web Services, rest, express, Node.js, Big Data, iot, Data Science, Cloud Computing, saas, Aws',\n",
       " 'Hadoop, Spark, Digital Strategy, Data Architecture, Command Center, Cdp, Dmp, Kafka, Data Science, Data Analysis, Big Data Analytics, Real Time Analysis, SQL',\n",
       " 'Analytics, Business Intelligence, Business Analytics, Predictive Modeling, Predictive Analytics, Data Science, Data Analysis, Data Analytics, Big Data, Big',\n",
       " 'Data Science',\n",
       " 'Machine Learning, algorithms, Go Getter, Computer Science, spark, Big Data, hdfs, sql, cassandra, hadoop, python, scala, java, Data Science, Front End',\n",
       " 'Technical Training, Software Development, Presentation Skills, B.tech, M.tech, B.e., mca, msc, Computer Science, freshers, jobs in indore, Data Science, itil',\n",
       " 'Software Development, It Sales, Account Management, Data Analysis, Customer Service, Sr, Software Engineering, Mvc, Ajax, Asp.net, Html, C#, Javascript',\n",
       " 'Qa, Ui/ux, Java Developer, Java Architect, C++/qt, Php, Lamp, Api, J2ee, Java, Soa, Esb, Middleware, Bigdata Achitect, Hadoop Architect, Deep',\n",
       " 'Business Intelligence, Data Warehousing, Data Science, Business Analytics, Customer Support, Business Reporting, Bi',\n",
       " 'Office Administration, Hr Administration, telecalling, client relationship management, Client Acquisition, Sales, Reception, HR, Recruitment, Onboarding, Human',\n",
       " 'Social Media, digital media maketing, seo, smm, smo, sem, Content Wirting, social media marketing, social media manager, digital media marketing manager',\n",
       " 'Data Science, Python, Data Analytics',\n",
       " 'Oracle Dba, Data Science, Data Warehousing, ETL, Jupyter, Numpy, Data Transformation, Snowflake, Teradata, Python, Data Manipulation, Relational Databases',\n",
       " 'Big Data, Hadoop, Data Analytics, Data Science',\n",
       " 'React.js, Data Science, Java, Front End, Business Analytics, Backend, Tableau, Python, Qa Testing, Automation Testing',\n",
       " 'Qlikview, Qlik Sense, Microsoft Azure, Power Bi, Data Science, Machine Learning',\n",
       " 'Telecalling, Client Interaction, Marketing, Research, Web Development, Social Media Marketing, Data Entry Operation, Excel, Ms Office, Invoicing',\n",
       " 'Data Science',\n",
       " 'Corporate Sales, Software Development, Software Sales, Marketing, Creative Designing, Corporate Planning, Senior Management, Crm, Client Relationship',\n",
       " 'Data Analytics, Data Science, Machine Learning, Deep Learning, Nlp, Data Mining, Python, R, Database Administration, Text Mining',\n",
       " 'Data Science, Machine Learning, Python, R, Deep Learning, Big Data, Hadoop',\n",
       " 'Big Data, Data Science, Artificial Intelligence, Hadoop, Ui Development, Php, Freelancing, .Net, Software Testing, Sap, Leadership Hiring',\n",
       " 'Java, Net, Angularjs, Hr, Infrastructure, Management, Project Management, Business Analysis, Data Science, Information Technology, Technology',\n",
       " 'Data Science, Artificial Intelligence, Machine Learning, Data Analytics',\n",
       " 'Software Architecture, Vp Engineering, Product Management, analytics, Data Science, Node.js, Principal Engineer, Big Data, python, angularjs, React.js',\n",
       " 'Data Science, Hadoop, Rpas, Devops, Python, Aws, Teaching, Big Data',\n",
       " 'Signal Processing, Machine Learning, Neural Networks, Data Science, Predictive Analytics, Time Series Analysis, Data Visualization, Technical Leadership, Data',\n",
       " 'Web Technologies, Project Management, Software Architecture, Data Science, Object Oriented Programming, Computer Science, Electrical Engineering, Architecture',\n",
       " 'Server Administartion, Verilog, Vhdl, Digital Marketing, Market Research, Property Research, Legal, It And Non It Recruitment, Logistics, Supply Chain, Bfsi',\n",
       " 'Data Analytics, Managed Services, Team Leading, python, Machine Learning, Google Analytics, Dmp, Aws, Campaign Analytics, Digital Campaigns, Audience',\n",
       " 'c++, Core Java, kdb, high frequency trading, hft, direct market access, Algorithmic Trading, Quant Development, Market Data, Fpga, Exchange Connectivity',\n",
       " 'Ethical Hacking, Security Operations Center, SOC, Managed Services, Data Science, Machine Learning, Artificial Intelligence, Operations Research, Education',\n",
       " 'Data Science, Artificial Intelligence, analytics, Business Intelligence, python, tableau, Power Bi, qlikview, sql, Data Warehousing, Data Visualization',\n",
       " 'Machine Learning, Artificial Intelligence, Data Science, Software Engineering, Software Development, Graduate Engineer Trainee, Fresher, Data Analytics, Java',\n",
       " 'C, C++, Artificial Intelligence, Python, Php, Web Development, Matlab, Data Science, Augmented Reality, C C++',\n",
       " 'Relationship Management, Retail Sales, Private Banking, Mutual Funds, NISM, Equity, Finance, Financial Products, Financial Services, Verbal, Written',\n",
       " 'Data Science, Software Engineering',\n",
       " 'Data Science, Big Data Analytics, Digital Marketing, Content Writing, Ui Development, Database Development, Qa Automation, Python, Project Management',\n",
       " 'Data Science, Recruitment, Salary',\n",
       " 'B.Tech, Tableau, Statistics, R, Analytics, Time Series, Data Science, Business Solutions, SQL, Technical Skills, SSAS, SQL Server, Analysis Services, Qlikview',\n",
       " 'Software Development, Business Intelligence, Big Data Analytics, Database Administration, Data Science, Microsoft Azure, Spark, Cassandra, Object Oriented',\n",
       " 'Data Science, Node.js, Angularjs',\n",
       " 'Data Science, Media Marketing, Resource Planning, Managed Services, Display Advertising, Machine Learning, Python, Etl, Sql',\n",
       " 'Data Analysis, Learning, Data Science, Computer Science, Communication Skills',\n",
       " 'Java, Hadoop, R, Machine Learning, Spark, Flume, Hdfs, Data Mining, Sas, Big, Data Science, Cloudera, Impala, Bigdata',\n",
       " 'Software Development, Core Java, Unit Testing, Customer Experience, Problem Solving, Communication Skills, Mysql, Data Science, Sales Management, Analytics',\n",
       " 'Machine Learning, Data Science, Product Management, New Product, Data Analysis, Computer Vision, Deep Learning, Python, Remote Sensing']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill = []\n",
    "skills = driver.find_elements(By.XPATH,\"//div[@class='hireSec highlightable']\")\n",
    "for i in skills:\n",
    "    skill.append(i.text)\n",
    "    \n",
    "skill    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "49a28b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b952fc4",
   "metadata": {},
   "source": [
    "## Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1723475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ad50560",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'C:\\Users\\Administrator\\Downloads\\chromedriver_win32.zip\\chromedriver.exe')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c874aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.imdb.com/list/ls095964455/'\n",
    "driver.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03cb19a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. Game of Thrones (2011–2019)',\n",
       " '2. Stranger Things (2016– )',\n",
       " '3. The Walking Dead (2010–2022)',\n",
       " '4. 13 Reasons Why (2017–2020)',\n",
       " '5. The 100 (2014–2020)',\n",
       " '6. Orange Is the New Black (2013–2019)',\n",
       " '7. Riverdale (2017– )',\n",
       " \"8. Grey's Anatomy (2005– )\",\n",
       " '9. The Flash (2014–2023)',\n",
       " '10. Arrow (2012–2020)',\n",
       " '11. Money Heist (2017–2021)',\n",
       " '12. The Big Bang Theory (2007–2019)',\n",
       " '13. Black Mirror (2011–2019)',\n",
       " '14. Sherlock (2010–2017)',\n",
       " '15. Vikings (2013–2020)',\n",
       " '16. Pretty Little Liars (2010–2017)',\n",
       " '17. The Vampire Diaries (2009–2017)',\n",
       " '18. American Horror Story (2011– )',\n",
       " '19. Breaking Bad (2008–2013)',\n",
       " '20. Lucifer (2016–2021)',\n",
       " '21. Supernatural (2005–2020)',\n",
       " '22. Prison Break (2005–2017)',\n",
       " '23. How to Get Away with Murder (2014–2020)',\n",
       " '24. Teen Wolf (2011–2017)',\n",
       " '25. The Simpsons (1989– )',\n",
       " '26. Once Upon a Time (2011–2018)',\n",
       " '27. Narcos (2015–2017)',\n",
       " '28. Daredevil (2015–2018)',\n",
       " '29. Friends (1994–2004)',\n",
       " '30. How I Met Your Mother (2005–2014)',\n",
       " '31. Suits (2011–2019)',\n",
       " '32. Mr. Robot (2015–2019)',\n",
       " '33. The Originals (2013–2018)',\n",
       " '34. Supergirl (2015–2021)',\n",
       " '35. Gossip Girl (2007–2012)',\n",
       " '36. Sense8 (2015–2018)',\n",
       " '37. Gotham (2014–2019)',\n",
       " '38. Westworld (2016–2022)',\n",
       " '39. Jessica Jones (2015–2019)',\n",
       " '40. Modern Family (2009–2020)',\n",
       " '41. Rick and Morty (2013– )',\n",
       " '42. Shadowhunters (2016–2019)',\n",
       " '43. The End of the F***ing World (2017–2019)',\n",
       " '44. House of Cards (2013–2018)',\n",
       " '45. Dark (2017–2020)',\n",
       " '46. Elite (2018– )',\n",
       " '47. Sex Education (2019– )',\n",
       " '48. Shameless (2011–2021)',\n",
       " '49. New Girl (2011–2018)',\n",
       " '50. Agents of S.H.I.E.L.D. (2013–2020)',\n",
       " '51. You (2018– )',\n",
       " '52. Dexter (2006–2013)',\n",
       " '53. Fear the Walking Dead (2015– )',\n",
       " '54. Family Guy (1999– )',\n",
       " '55. The Blacklist (2013– )',\n",
       " '56. Lost (2004–2010)',\n",
       " '57. Peaky Blinders (2013–2022)',\n",
       " '58. House (2004–2012)',\n",
       " '59. Quantico (2015–2018)',\n",
       " '60. Orphan Black (2013–2017)',\n",
       " '61. Homeland (2011–2020)',\n",
       " '62. Blindspot (2015–2020)',\n",
       " \"63. DC's Legends of Tomorrow (2016–2022)\",\n",
       " \"64. The Handmaid's Tale (2017– )\",\n",
       " '65. Chilling Adventures of Sabrina (2018–2020)',\n",
       " '66. The Good Doctor (2017– )',\n",
       " '67. Jane the Virgin (2014–2019)',\n",
       " '68. Glee (2009–2015)',\n",
       " '69. South Park (1997– )',\n",
       " '70. Brooklyn Nine-Nine (2013–2021)',\n",
       " '71. Under the Dome (2013–2015)',\n",
       " '72. The Umbrella Academy (2019–2023)',\n",
       " '73. True Detective (2014–2019)',\n",
       " '74. The OA (2016–2019)',\n",
       " '75. Desperate Housewives (2004–2012)',\n",
       " '76. Better Call Saul (2015–2022)',\n",
       " '77. Bates Motel (2013–2017)',\n",
       " '78. The Punisher (2017–2019)',\n",
       " '79. Atypical (2017–2021)',\n",
       " '80. Dynasty (2017–2022)',\n",
       " '81. This Is Us (2016–2022)',\n",
       " '82. The Good Place (2016–2020)',\n",
       " '83. Iron Fist (2017–2018)',\n",
       " '84. The Rain (2018–2020)',\n",
       " '85. Mindhunter (2017–2019)',\n",
       " '86. Revenge (2011–2015)',\n",
       " '87. Luke Cage (2016–2018)',\n",
       " '88. Scandal (2012–2018)',\n",
       " '89. The Defenders (2017)',\n",
       " '90. Big Little Lies (2017–2019)',\n",
       " '91. Insatiable (2018–2019)',\n",
       " '92. The Mentalist (2008–2015)',\n",
       " '93. The Crown (2016– )',\n",
       " '94. Chernobyl (2019)',\n",
       " '95. iZombie (2015–2019)',\n",
       " '96. Reign (2013–2017)',\n",
       " '97. A Series of Unfortunate Events (2017–2019)',\n",
       " '98. Criminal Minds (2005– )',\n",
       " '99. Scream: The TV Series (2015–2019)',\n",
       " '100. The Haunting of Hill House (2018)']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = []\n",
    "names = driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']\")\n",
    "for i in names:\n",
    "    name.append(i.text)\n",
    "    \n",
    "    \n",
    "name    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7d1e853a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(2011–2019)',\n",
       " '(2016– )',\n",
       " '(2010–2022)',\n",
       " '(2017–2020)',\n",
       " '(2014–2020)',\n",
       " '(2013–2019)',\n",
       " '(2017– )',\n",
       " '(2005– )',\n",
       " '(2014–2023)',\n",
       " '(2012–2020)',\n",
       " '(2017–2021)',\n",
       " '(2007–2019)',\n",
       " '(2011–2019)',\n",
       " '(2010–2017)',\n",
       " '(2013–2020)',\n",
       " '(2010–2017)',\n",
       " '(2009–2017)',\n",
       " '(2011– )',\n",
       " '(2008–2013)',\n",
       " '(2016–2021)',\n",
       " '(2005–2020)',\n",
       " '(2005–2017)',\n",
       " '(2014–2020)',\n",
       " '(2011–2017)',\n",
       " '(1989– )',\n",
       " '(2011–2018)',\n",
       " '(2015–2017)',\n",
       " '(2015–2018)',\n",
       " '(1994–2004)',\n",
       " '(2005–2014)',\n",
       " '(2011–2019)',\n",
       " '(2015–2019)',\n",
       " '(2013–2018)',\n",
       " '(2015–2021)',\n",
       " '(2007–2012)',\n",
       " '(2015–2018)',\n",
       " '(2014–2019)',\n",
       " '(2016–2022)',\n",
       " '(2015–2019)',\n",
       " '(2009–2020)',\n",
       " '(2013– )',\n",
       " '(2016–2019)',\n",
       " '(2017–2019)',\n",
       " '(2013–2018)',\n",
       " '(2017–2020)',\n",
       " '(2018– )',\n",
       " '(2019– )',\n",
       " '(2011–2021)',\n",
       " '(2011–2018)',\n",
       " '(2013–2020)',\n",
       " '(2018– )',\n",
       " '(2006–2013)',\n",
       " '(2015– )',\n",
       " '(1999– )',\n",
       " '(2013– )',\n",
       " '(2004–2010)',\n",
       " '(2013–2022)',\n",
       " '(2004–2012)',\n",
       " '(2015–2018)',\n",
       " '(2013–2017)',\n",
       " '(2011–2020)',\n",
       " '(2015–2020)',\n",
       " '(2016–2022)',\n",
       " '(2017– )',\n",
       " '(2018–2020)',\n",
       " '(2017– )',\n",
       " '(2014–2019)',\n",
       " '(2009–2015)',\n",
       " '(1997– )',\n",
       " '(2013–2021)',\n",
       " '(2013–2015)',\n",
       " '(2019–2023)',\n",
       " '(2014–2019)',\n",
       " '(2016–2019)',\n",
       " '(2004–2012)',\n",
       " '(2015–2022)',\n",
       " '(2013–2017)',\n",
       " '(2017–2019)',\n",
       " '(2017–2021)',\n",
       " '(2017–2022)',\n",
       " '(2016–2022)',\n",
       " '(2016–2020)',\n",
       " '(2017–2018)',\n",
       " '(2018–2020)',\n",
       " '(2017–2019)',\n",
       " '(2011–2015)',\n",
       " '(2016– )',\n",
       " '(2012–2018)',\n",
       " '(2017)',\n",
       " '(2017–2019)',\n",
       " '(2018–2019)',\n",
       " '(2008–2015)',\n",
       " '(2016– )',\n",
       " '(2019)',\n",
       " '(2015–2019)',\n",
       " '(2013–2017)',\n",
       " '(2017–2019)',\n",
       " '(2005– )',\n",
       " '(2015–2019)',\n",
       " '(2018)']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yr_span =[]\n",
    "years = driver.find_elements(By.XPATH,\"//span[@class='lister-item-year text-muted unbold']\")\n",
    "for i in years:\n",
    "    yr_span.append(i.text)\n",
    "    \n",
    "    \n",
    "yr_span    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8c5911b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.2',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '8.7',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '8.1',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '7.5',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '7.6',\n",
       " '',\n",
       " 'Rate',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = []\n",
    "ratings = driver.find_elements(By.XPATH,\"//span[@class='ipl-rating-star__rating']\")\n",
    "for i in ratings[0:100]:\n",
    "    rating.append(i.text)\n",
    "    \n",
    "rating    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "16e6bc52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,090,195',\n",
       " '1,179,754',\n",
       " '989,016',\n",
       " '292,882',\n",
       " '252,016',\n",
       " '302,934',\n",
       " '145,520',\n",
       " '308,925',\n",
       " '346,341',\n",
       " '431,992',\n",
       " '476,094',\n",
       " '807,189',\n",
       " '545,711',\n",
       " '924,321',\n",
       " '531,740',\n",
       " '168,042',\n",
       " '322,291',\n",
       " '319,673',\n",
       " '1,872,826',\n",
       " '324,428',\n",
       " '445,685',\n",
       " '535,351',\n",
       " '152,267',\n",
       " '148,940',\n",
       " '407,492',\n",
       " '225,445',\n",
       " '421,985',\n",
       " '440,852',\n",
       " '992,824',\n",
       " '683,160',\n",
       " '410,858',\n",
       " '387,718',\n",
       " '136,607',\n",
       " '124,427',\n",
       " '175,466',\n",
       " '155,006',\n",
       " '230,943',\n",
       " '504,987',\n",
       " '215,204',\n",
       " '430,642',\n",
       " '519,598',\n",
       " '64,111',\n",
       " '190,861',\n",
       " '504,654',\n",
       " '385,129',\n",
       " '79,655',\n",
       " '280,580',\n",
       " '243,394',\n",
       " '225,087',\n",
       " '217,663',\n",
       " '240,395',\n",
       " '725,438',\n",
       " '130,413',\n",
       " '339,932',\n",
       " '249,772',\n",
       " '553,496',\n",
       " '546,391',\n",
       " '464,911',\n",
       " '61,274',\n",
       " '111,547',\n",
       " '342,050',\n",
       " '74,406',\n",
       " '105,242',\n",
       " '237,084',\n",
       " '95,787',\n",
       " '95,520',\n",
       " '51,151',\n",
       " '149,002',\n",
       " '369,614',\n",
       " '316,156',\n",
       " '107,037',\n",
       " '248,264',\n",
       " '570,398',\n",
       " '105,448',\n",
       " '129,618',\n",
       " '525,317',\n",
       " '108,729',\n",
       " '236,561',\n",
       " '89,462',\n",
       " '22,878',\n",
       " '144,412',\n",
       " '160,689',\n",
       " '131,738',\n",
       " '37,603',\n",
       " '288,708',\n",
       " '120,486',\n",
       " '131,838',\n",
       " '74,332',\n",
       " '108,500',\n",
       " '199,587',\n",
       " '29,121',\n",
       " '185,731',\n",
       " '216,712',\n",
       " '748,620',\n",
       " '68,694',\n",
       " '50,190',\n",
       " '61,462',\n",
       " '198,351',\n",
       " '41,579',\n",
       " '245,251']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "votes = []\n",
    "vote = driver.find_elements(By.XPATH,\"//span[@name='nv']\")\n",
    "for i in vote:\n",
    "    votes.append(i.text)\n",
    "    \n",
    "votes    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b5962aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['57 min',\n",
       " '51 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '43 min',\n",
       " '59 min',\n",
       " '45 min',\n",
       " '41 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '70 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '88 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '41 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '54 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '44 min',\n",
       " '49 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '42 min',\n",
       " '62 min',\n",
       " '56 min',\n",
       " '22 min',\n",
       " '23 min',\n",
       " '42 min',\n",
       " '25 min',\n",
       " '51 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '22 min',\n",
       " '45 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '41 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '55 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '30 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '22 min',\n",
       " '55 min',\n",
       " '45 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '43 min',\n",
       " '50 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '58 min',\n",
       " '330 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '50 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '572 min']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_time = []\n",
    "times = driver.find_elements(By.XPATH,\"//span[@class='runtime']\")\n",
    "for i in times:\n",
    "    run_time.append(i.text)\n",
    "    \n",
    "run_time    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0fdec100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action, Adventure, Drama',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Thriller',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Mystery, Romance',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Crime, Drama, Fantasy',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Animation, Comedy',\n",
       " 'Adventure, Fantasy, Romance',\n",
       " 'Biography, Crime, Drama',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Drama',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Animation, Adventure, Comedy',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Adventure, Comedy, Crime',\n",
       " 'Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Crime, Drama, Romance',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Animation, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Adventure, Drama, Fantasy',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Mystery',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama',\n",
       " 'Comedy',\n",
       " 'Comedy, Drama, Music',\n",
       " 'Animation, Comedy',\n",
       " 'Comedy, Crime',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Adventure, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Fantasy, Mystery',\n",
       " 'Comedy, Drama, Mystery',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Horror, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Comedy, Drama, Fantasy',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Thriller',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Drama, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Biography, Drama, History',\n",
       " 'Drama, History, Thriller',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama',\n",
       " 'Adventure, Comedy, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama, Horror, Mystery']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre = []\n",
    "genres = driver.find_elements(By.XPATH,\"//span[@class='genre']\")\n",
    "for i in genres:\n",
    "    genre.append(i.text)\n",
    "\n",
    "genre    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "248ad44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633e6c98",
   "metadata": {},
   "source": [
    "## Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "153a7af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95c5a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'C:\\Users\\Administrator\\Downloads\\chromedriver_win32.zip\\chromedriver.exe')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a013eed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare'\n",
    "driver.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a3ee15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Da Vinci Code,The',\n",
       " 'Harry Potter and the Deathly Hallows',\n",
       " \"Harry Potter and the Philosopher's Stone\",\n",
       " 'Harry Potter and the Order of the Phoenix',\n",
       " 'Fifty Shades of Grey',\n",
       " 'Harry Potter and the Goblet of Fire',\n",
       " 'Harry Potter and the Chamber of Secrets',\n",
       " 'Harry Potter and the Prisoner of Azkaban',\n",
       " 'Angels and Demons',\n",
       " \"Harry Potter and the Half-blood Prince:Children's Edition\",\n",
       " 'Fifty Shades Darker',\n",
       " 'Twilight',\n",
       " 'Girl with the Dragon Tattoo,The:Millennium Trilogy',\n",
       " 'Fifty Shades Freed',\n",
       " 'Lost Symbol,The',\n",
       " 'New Moon',\n",
       " 'Deception Point',\n",
       " 'Eclipse',\n",
       " 'Lovely Bones,The',\n",
       " 'Curious Incident of the Dog in the Night-time,The',\n",
       " 'Digital Fortress',\n",
       " 'Short History of Nearly Everything,A',\n",
       " 'Girl Who Played with Fire,The:Millennium Trilogy',\n",
       " 'Breaking Dawn',\n",
       " 'Very Hungry Caterpillar,The:The Very Hungry Caterpillar',\n",
       " 'Gruffalo,The',\n",
       " \"Jamie's 30-Minute Meals\",\n",
       " 'Kite Runner,The',\n",
       " 'One Day',\n",
       " 'Thousand Splendid Suns,A',\n",
       " \"Girl Who Kicked the Hornets' Nest,The:Millennium Trilogy\",\n",
       " \"Time Traveler's Wife,The\",\n",
       " 'Atonement',\n",
       " \"Bridget Jones's Diary:A Novel\",\n",
       " 'World According to Clarkson,The',\n",
       " \"Captain Corelli's Mandolin\",\n",
       " 'Sound of Laughter,The',\n",
       " 'Life of Pi',\n",
       " 'Billy Connolly',\n",
       " 'Child Called It,A',\n",
       " \"Gruffalo's Child,The\",\n",
       " \"Angela's Ashes:A Memoir of a Childhood\",\n",
       " 'Birdsong',\n",
       " 'Northern Lights:His Dark Materials S.',\n",
       " 'Labyrinth',\n",
       " 'Harry Potter and the Half-blood Prince',\n",
       " 'Help,The',\n",
       " 'Man and Boy',\n",
       " 'Memoirs of a Geisha',\n",
       " \"No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S.\",\n",
       " 'Island,The',\n",
       " 'PS, I Love You',\n",
       " 'You are What You Eat:The Plan That Will Change Your Life',\n",
       " 'Shadow of the Wind,The',\n",
       " 'Tales of Beedle the Bard,The',\n",
       " 'Broker,The',\n",
       " \"Dr. Atkins' New Diet Revolution:The No-hunger, Luxurious Weight Loss P\",\n",
       " 'Subtle Knife,The:His Dark Materials S.',\n",
       " 'Eats, Shoots and Leaves:The Zero Tolerance Approach to Punctuation',\n",
       " \"Delia's How to Cook:(Bk.1)\",\n",
       " 'Chocolat',\n",
       " 'Boy in the Striped Pyjamas,The',\n",
       " \"My Sister's Keeper\",\n",
       " 'Amber Spyglass,The:His Dark Materials S.',\n",
       " 'To Kill a Mockingbird',\n",
       " 'Men are from Mars, Women are from Venus:A Practical Guide for Improvin',\n",
       " 'Dear Fatty',\n",
       " 'Short History of Tractors in Ukrainian,A',\n",
       " 'Hannibal',\n",
       " 'Lord of the Rings,The',\n",
       " 'Stupid White Men:...and Other Sorry Excuses for the State of the Natio',\n",
       " 'Interpretation of Murder,The',\n",
       " 'Sharon Osbourne Extreme:My Autobiography',\n",
       " 'Alchemist,The:A Fable About Following Your Dream',\n",
       " \"At My Mother's Knee ...:and Other Low Joints\",\n",
       " 'Notes from a Small Island',\n",
       " 'Return of the Naked Chef,The',\n",
       " 'Bridget Jones: The Edge of Reason',\n",
       " \"Jamie's Italy\",\n",
       " 'I Can Make You Thin',\n",
       " 'Down Under',\n",
       " 'Summons,The',\n",
       " 'Small Island',\n",
       " 'Nigella Express',\n",
       " 'Brick Lane',\n",
       " \"Memory Keeper's Daughter,The\",\n",
       " 'Room on the Broom',\n",
       " 'About a Boy',\n",
       " 'My Booky Wook',\n",
       " 'God Delusion,The',\n",
       " '\"Beano\" Annual,The',\n",
       " 'White Teeth',\n",
       " 'House at Riverton,The',\n",
       " 'Book Thief,The',\n",
       " 'Nights of Rain and Stars',\n",
       " 'Ghost,The',\n",
       " 'Happy Days with the Naked Chef',\n",
       " 'Hunger Games,The:Hunger Games Trilogy',\n",
       " \"Lost Boy,The:A Foster Child's Search for the Love of a Family\",\n",
       " \"Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_name = []\n",
    "books = driver.find_elements(By.XPATH,\"//table[@class='in-article sortable'][1]/tbody/tr/td[2]\")\n",
    "for i in books:\n",
    "    book_name.append(i.text)\n",
    "    \n",
    "book_name    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6390781a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brown, Dan',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'James, E. L.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Brown, Dan',\n",
       " 'Rowling, J.K.',\n",
       " 'James, E. L.',\n",
       " 'Meyer, Stephenie',\n",
       " 'Larsson, Stieg',\n",
       " 'James, E. L.',\n",
       " 'Brown, Dan',\n",
       " 'Meyer, Stephenie',\n",
       " 'Brown, Dan',\n",
       " 'Meyer, Stephenie',\n",
       " 'Sebold, Alice',\n",
       " 'Haddon, Mark',\n",
       " 'Brown, Dan',\n",
       " 'Bryson, Bill',\n",
       " 'Larsson, Stieg',\n",
       " 'Meyer, Stephenie',\n",
       " 'Carle, Eric',\n",
       " 'Donaldson, Julia',\n",
       " 'Oliver, Jamie',\n",
       " 'Hosseini, Khaled',\n",
       " 'Nicholls, David',\n",
       " 'Hosseini, Khaled',\n",
       " 'Larsson, Stieg',\n",
       " 'Niffenegger, Audrey',\n",
       " 'McEwan, Ian',\n",
       " 'Fielding, Helen',\n",
       " 'Clarkson, Jeremy',\n",
       " 'Bernieres, Louis de',\n",
       " 'Kay, Peter',\n",
       " 'Martel, Yann',\n",
       " 'Stephenson, Pamela',\n",
       " 'Pelzer, Dave',\n",
       " 'Donaldson, Julia',\n",
       " 'McCourt, Frank',\n",
       " 'Faulks, Sebastian',\n",
       " 'Pullman, Philip',\n",
       " 'Mosse, Kate',\n",
       " 'Rowling, J.K.',\n",
       " 'Stockett, Kathryn',\n",
       " 'Parsons, Tony',\n",
       " 'Golden, Arthur',\n",
       " 'McCall Smith, Alexander',\n",
       " 'Hislop, Victoria',\n",
       " 'Ahern, Cecelia',\n",
       " 'McKeith, Gillian',\n",
       " 'Zafon, Carlos Ruiz',\n",
       " 'Rowling, J.K.',\n",
       " 'Grisham, John',\n",
       " 'Atkins, Robert C.',\n",
       " 'Pullman, Philip',\n",
       " 'Truss, Lynne',\n",
       " 'Smith, Delia',\n",
       " 'Harris, Joanne',\n",
       " 'Boyne, John',\n",
       " 'Picoult, Jodi',\n",
       " 'Pullman, Philip',\n",
       " 'Lee, Harper',\n",
       " 'Gray, John',\n",
       " 'French, Dawn',\n",
       " 'Lewycka, Marina',\n",
       " 'Harris, Thomas',\n",
       " 'Tolkien, J. R. R.',\n",
       " 'Moore, Michael',\n",
       " 'Rubenfeld, Jed',\n",
       " 'Osbourne, Sharon',\n",
       " 'Coelho, Paulo',\n",
       " \"O'Grady, Paul\",\n",
       " 'Bryson, Bill',\n",
       " 'Oliver, Jamie',\n",
       " 'Fielding, Helen',\n",
       " 'Oliver, Jamie',\n",
       " 'McKenna, Paul',\n",
       " 'Bryson, Bill',\n",
       " 'Grisham, John',\n",
       " 'Levy, Andrea',\n",
       " 'Lawson, Nigella',\n",
       " 'Ali, Monica',\n",
       " 'Edwards, Kim',\n",
       " 'Donaldson, Julia',\n",
       " 'Hornby, Nick',\n",
       " 'Brand, Russell',\n",
       " 'Dawkins, Richard',\n",
       " '0',\n",
       " 'Smith, Zadie',\n",
       " 'Morton, Kate',\n",
       " 'Zusak, Markus',\n",
       " 'Binchy, Maeve',\n",
       " 'Harris, Robert',\n",
       " 'Oliver, Jamie',\n",
       " 'Collins, Suzanne',\n",
       " 'Pelzer, Dave',\n",
       " 'Oliver, Jamie']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_name = []\n",
    "authors = driver.find_elements(By.XPATH,\"//table[@class='in-article sortable'][1]/tbody/tr/td[3]\")\n",
    "for i in authors:\n",
    "    author_name.append(i.text)\n",
    "    \n",
    "author_name    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "188ef027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5,094,805',\n",
       " '4,475,152',\n",
       " '4,200,654',\n",
       " '4,179,479',\n",
       " '3,758,936',\n",
       " '3,583,215',\n",
       " '3,484,047',\n",
       " '3,377,906',\n",
       " '3,193,946',\n",
       " '2,950,264',\n",
       " '2,479,784',\n",
       " '2,315,405',\n",
       " '2,233,570',\n",
       " '2,193,928',\n",
       " '2,183,031',\n",
       " '2,152,737',\n",
       " '2,062,145',\n",
       " '2,052,876',\n",
       " '2,005,598',\n",
       " '1,979,552',\n",
       " '1,928,900',\n",
       " '1,852,919',\n",
       " '1,814,784',\n",
       " '1,787,118',\n",
       " '1,783,535',\n",
       " '1,781,269',\n",
       " '1,743,266',\n",
       " '1,629,119',\n",
       " '1,616,068',\n",
       " '1,583,992',\n",
       " '1,555,135',\n",
       " '1,546,886',\n",
       " '1,539,428',\n",
       " '1,508,205',\n",
       " '1,489,403',\n",
       " '1,352,318',\n",
       " '1,310,207',\n",
       " '1,310,176',\n",
       " '1,231,957',\n",
       " '1,217,712',\n",
       " '1,208,711',\n",
       " '1,204,058',\n",
       " '1,184,967',\n",
       " '1,181,503',\n",
       " '1,181,093',\n",
       " '1,153,181',\n",
       " '1,132,336',\n",
       " '1,130,802',\n",
       " '1,126,337',\n",
       " '1,115,549',\n",
       " '1,108,328',\n",
       " '1,107,379',\n",
       " '1,104,403',\n",
       " '1,092,349',\n",
       " '1,090,847',\n",
       " '1,087,262',\n",
       " '1,054,196',\n",
       " '1,037,160',\n",
       " '1,023,688',\n",
       " '1,015,956',\n",
       " '1,009,873',\n",
       " '1,004,414',\n",
       " '1,003,780',\n",
       " '1,002,314',\n",
       " '998,213',\n",
       " '992,846',\n",
       " '986,753',\n",
       " '986,115',\n",
       " '970,509',\n",
       " '967,466',\n",
       " '963,353',\n",
       " '962,515',\n",
       " '959,496',\n",
       " '956,114',\n",
       " '945,640',\n",
       " '931,312',\n",
       " '925,425',\n",
       " '924,695',\n",
       " '906,968',\n",
       " '905,086',\n",
       " '890,847',\n",
       " '869,671',\n",
       " '869,659',\n",
       " '862,602',\n",
       " '856,540',\n",
       " '845,858',\n",
       " '842,535',\n",
       " '828,215',\n",
       " '820,563',\n",
       " '816,907',\n",
       " '816,585',\n",
       " '815,586',\n",
       " '814,370',\n",
       " '809,641',\n",
       " '808,900',\n",
       " '807,311',\n",
       " '794,201',\n",
       " '792,187',\n",
       " '791,507',\n",
       " '791,095']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_sales = []\n",
    "values = driver.find_elements(By.XPATH,\"//table[@class='in-article sortable'][1]/tbody/tr/td[4]\")\n",
    "for i in values:\n",
    "    val_sales.append(i.text)\n",
    "    \n",
    "val_sales    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd20e96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Transworld',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Transworld',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Little, Brown Book',\n",
       " 'Quercus',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Little, Brown Book',\n",
       " 'Transworld',\n",
       " 'Little, Brown Book',\n",
       " 'Pan Macmillan',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Quercus',\n",
       " 'Little, Brown Book',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Bloomsbury',\n",
       " 'Hodder & Stoughton',\n",
       " 'Bloomsbury',\n",
       " 'Quercus',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Canongate',\n",
       " 'HarperCollins',\n",
       " 'Orion',\n",
       " 'Pan Macmillan',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Scholastic Ltd.',\n",
       " 'Orion',\n",
       " 'Bloomsbury',\n",
       " 'Penguin',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Little, Brown Book',\n",
       " 'Headline',\n",
       " 'HarperCollins',\n",
       " 'Penguin',\n",
       " 'Orion',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Scholastic Ltd.',\n",
       " 'Profile Books Group',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Random House Childrens Books G',\n",
       " 'Hodder & Stoughton',\n",
       " 'Scholastic Ltd.',\n",
       " 'Random House',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Penguin',\n",
       " 'Random House',\n",
       " 'HarperCollins',\n",
       " 'Penguin',\n",
       " 'Headline',\n",
       " 'Little, Brown Book',\n",
       " 'HarperCollins',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Random House',\n",
       " 'Headline',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Hodder & Stoughton',\n",
       " 'Transworld',\n",
       " 'D.C. Thomson',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Transworld',\n",
       " 'Orion',\n",
       " 'Random House',\n",
       " 'Penguin',\n",
       " 'Scholastic Ltd.',\n",
       " 'Orion',\n",
       " 'Penguin']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publisher = []\n",
    "publishers = driver.find_elements(By.XPATH,\"//table[@class='in-article sortable'][1]/tbody/tr/td[5]\")\n",
    "for i in publishers:\n",
    "    publisher.append(i.text)\n",
    "    \n",
    "publisher    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73ba373a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Crime, Thriller & Adventure',\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " 'Romance & Sagas',\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " 'Crime, Thriller & Adventure',\n",
       " \"Children's Fiction\",\n",
       " 'Romance & Sagas',\n",
       " 'Young Adult Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Romance & Sagas',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Popular Science',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'Picture Books',\n",
       " 'Picture Books',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Humour: Collections & General',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Biography: The Arts',\n",
       " 'Autobiography: General',\n",
       " 'Picture Books',\n",
       " 'Autobiography: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Science Fiction & Fantasy',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Fitness & Diet',\n",
       " 'General & Literary Fiction',\n",
       " \"Children's Fiction\",\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Fitness & Diet',\n",
       " 'Young Adult Fiction',\n",
       " 'Usage & Writing Guides',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Popular Culture & Media: General Interest',\n",
       " 'Autobiography: The Arts',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Science Fiction & Fantasy',\n",
       " 'Current Affairs & Issues',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Autobiography: The Arts',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: The Arts',\n",
       " 'Travel Writing',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'National & Regional Cuisine',\n",
       " 'Fitness & Diet',\n",
       " 'Travel Writing',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Picture Books',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: The Arts',\n",
       " 'Popular Science',\n",
       " \"Children's Annuals\",\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Food & Drink: General',\n",
       " 'Young Adult Fiction',\n",
       " 'Biography: General',\n",
       " 'Food & Drink: General']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre = []\n",
    "genres = driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[6]\")\n",
    "for i in genres:\n",
    "    genre.append(i.text)\n",
    "    \n",
    "genre    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f491f49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a17ffb",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c542ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "edf7658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'C:\\Users\\Administrator\\Downloads\\chromedriver_win32.zip\\chromedriver.exe')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50057003",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'http://statisticstimes.com/'\n",
    "driver.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "79c2c40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "economy_btn = driver.find_element(By.XPATH,\"//*[@id='top']/div[2]/div[2]/button\")\n",
    "economy_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "663dcb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "india_btn = driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")\n",
    "india_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aca1cf65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = []\n",
    "ranks = driver.find_elements(By.XPATH,\"//table[@id='table_id']/tbody/tr/td[1]\")\n",
    "for i in ranks:\n",
    "    rank.append(i.text)\n",
    "    \n",
    "rank    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "831d46d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Maharashtra',\n",
       " 'Tamil Nadu',\n",
       " 'Uttar Pradesh',\n",
       " 'Gujarat',\n",
       " 'Karnataka',\n",
       " 'West Bengal',\n",
       " 'Rajasthan',\n",
       " 'Andhra Pradesh',\n",
       " 'Telangana',\n",
       " 'Madhya Pradesh',\n",
       " 'Kerala',\n",
       " 'Delhi',\n",
       " 'Haryana',\n",
       " 'Bihar',\n",
       " 'Punjab',\n",
       " 'Odisha',\n",
       " 'Assam',\n",
       " 'Chhattisgarh',\n",
       " 'Jharkhand',\n",
       " 'Uttarakhand',\n",
       " 'Jammu & Kashmir',\n",
       " 'Himachal Pradesh',\n",
       " 'Goa',\n",
       " 'Tripura',\n",
       " 'Chandigarh',\n",
       " 'Puducherry',\n",
       " 'Meghalaya',\n",
       " 'Sikkim',\n",
       " 'Manipur',\n",
       " 'Nagaland',\n",
       " 'Arunachal Pradesh',\n",
       " 'Mizoram',\n",
       " 'Andaman & Nicobar Islands']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = []\n",
    "states = driver.find_elements(By.XPATH,\"//table[@id='table_id']/tbody/tr/td[2]\")\n",
    "for i in states:\n",
    "    state.append(i.text)\n",
    "    \n",
    "state    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b7cfb089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,632,792',\n",
       " '1,630,208',\n",
       " '1,584,764',\n",
       " '1,502,899',\n",
       " '1,493,127',\n",
       " '1,089,898',\n",
       " '942,586',\n",
       " '862,957',\n",
       " '861,031',\n",
       " '809,592',\n",
       " '781,653',\n",
       " '774,870',\n",
       " '734,163',\n",
       " '530,363',\n",
       " '526,376',\n",
       " '487,805',\n",
       " '315,881',\n",
       " '304,063',\n",
       " '297,204',\n",
       " '245,895',\n",
       " '155,956',\n",
       " '153,845',\n",
       " '73,170',\n",
       " '49,845',\n",
       " '42,114',\n",
       " '34,433',\n",
       " '33,481',\n",
       " '28,723',\n",
       " '27,870',\n",
       " '27,283',\n",
       " '24,603',\n",
       " '22,287',\n",
       " '-']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSDP = []\n",
    "GSDP_19 = driver.find_elements(By.XPATH,\"//table[@id='table_id']/tbody/tr/td[4]\")\n",
    "for i in GSDP_19:\n",
    "    GSDP.append(i.text)\n",
    "    \n",
    "GSDP    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dad390ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " '1,845,853',\n",
       " '1,687,818',\n",
       " '-',\n",
       " '1,631,977',\n",
       " '1,253,832',\n",
       " '1,020,989',\n",
       " '972,782',\n",
       " '969,604',\n",
       " '906,672',\n",
       " '-',\n",
       " '856,112',\n",
       " '831,610',\n",
       " '611,804',\n",
       " '574,760',\n",
       " '521,275',\n",
       " '-',\n",
       " '329,180',\n",
       " '328,598',\n",
       " '-',\n",
       " '-',\n",
       " '165,472',\n",
       " '80,449',\n",
       " '55,984',\n",
       " '-',\n",
       " '38,253',\n",
       " '36,572',\n",
       " '32,496',\n",
       " '31,790',\n",
       " '-',\n",
       " '-',\n",
       " '26,503',\n",
       " '-']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSDP = []\n",
    "GSDP_20 = driver.find_elements(By.XPATH,\"//table[@id='table_id']/tbody/tr/td[3]\")\n",
    "for i in GSDP_20:\n",
    "    GSDP.append(i.text)\n",
    "    \n",
    "GSDP    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d46eef42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['13.94%',\n",
       " '8.63%',\n",
       " '8.39%',\n",
       " '7.96%',\n",
       " '7.91%',\n",
       " '5.77%',\n",
       " '4.99%',\n",
       " '4.57%',\n",
       " '4.56%',\n",
       " '4.29%',\n",
       " '4.14%',\n",
       " '4.10%',\n",
       " '3.89%',\n",
       " '2.81%',\n",
       " '2.79%',\n",
       " '2.58%',\n",
       " '1.67%',\n",
       " '1.61%',\n",
       " '1.57%',\n",
       " '1.30%',\n",
       " '0.83%',\n",
       " '0.81%',\n",
       " '0.39%',\n",
       " '0.26%',\n",
       " '0.22%',\n",
       " '0.18%',\n",
       " '0.18%',\n",
       " '0.15%',\n",
       " '0.15%',\n",
       " '0.14%',\n",
       " '0.13%',\n",
       " '0.12%',\n",
       " '-']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "share = []\n",
    "shares = driver.find_elements(By.XPATH,\"//table[@id='table_id']/tbody/tr/td[5]\")\n",
    "for i in shares:\n",
    "    share.append(i.text)\n",
    "    \n",
    "share    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f1394cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['399.921',\n",
       " '247.629',\n",
       " '240.726',\n",
       " '228.290',\n",
       " '226.806',\n",
       " '165.556',\n",
       " '143.179',\n",
       " '131.083',\n",
       " '130.791',\n",
       " '122.977',\n",
       " '118.733',\n",
       " '117.703',\n",
       " '111.519',\n",
       " '80.562',\n",
       " '79.957',\n",
       " '74.098',\n",
       " '47.982',\n",
       " '46.187',\n",
       " '45.145',\n",
       " '37.351',\n",
       " '23.690',\n",
       " '23.369',\n",
       " '11.115',\n",
       " '7.571',\n",
       " '6.397',\n",
       " '5.230',\n",
       " '5.086',\n",
       " '4.363',\n",
       " '4.233',\n",
       " '4.144',\n",
       " '3.737',\n",
       " '3.385',\n",
       " '-']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDP = []\n",
    "GDP_bill = driver.find_elements(By.XPATH,\"//table[@id='table_id']/tbody/tr/td[6]\")\n",
    "for i in GDP_bill:\n",
    "    GDP.append(i.text)\n",
    "    \n",
    "GDP    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b56264cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0594aa55",
   "metadata": {},
   "source": [
    "## Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f98bab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd1b09f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'C:\\Users\\Administrator\\Downloads\\chromedriver_win32.zip\\chromedriver.exe')\n",
    "driver.maximize_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14346c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.billboard.com/'\n",
    "driver.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a093ea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn = driver.find_element(By.XPATH,\"//*[@id='mega-menu-item-charts']/a\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b52aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_btn = driver.find_element(By.XPATH,\"//*[@id='main-wrapper']/div[8]/div/div/div/ul/li[1]/ul/li[2]/a\")\n",
    "hot_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9dcc6bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_name=[]\n",
    "names=driver.find_elements(By.XPATH,\"//span[@class='chart-element__information__song text--truncate color--primary']\")\n",
    "for i in names:\n",
    "    song_name.append(i.text)\n",
    "    \n",
    "    \n",
    "song_name    \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaa8be3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
